{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b889eb53",
   "metadata": {},
   "source": [
    "<center><h2>Sorbonne université</h2></center>\n",
    "<center><h4>IAR - Intelligence artificielle pour la robotique</h4></center>\n",
    "<center><h4>M2 Artificial Intelligence</h4></center>\n",
    "<center><h1>Apprentissage par renforcement profond</h1></center>\n",
    "<center><h3>LunarLander-v2</h3></center>\n",
    "<br />\n",
    "<center><h4>Thomas CORCORAL - <a href=\"https://www.linkedin.com/in/thomas-corcoral/?locale=en_US\">linkedIn</a></h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3accd4",
   "metadata": {},
   "source": [
    "# 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a749827",
   "metadata": {},
   "source": [
    "## 1.1 git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c30170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ThomasCorcoral/rl-baselines3-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv rl-baselines3-zoo/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r rl-baselines3-zoo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266955b3",
   "metadata": {},
   "source": [
    "## 1.2 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f02e24",
   "metadata": {},
   "source": [
    "Some corrections to support different environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install Box2D\n",
    "!pip3 install box2d-py\n",
    "!pip3 install gym[all]\n",
    "!pip3 install gym[Box_2D] # To support all envs (some problems with Box_2D on Kaggle)\n",
    "!pip install sb3-contrib\n",
    "!pip install pyglet\n",
    "!pip install huggingface_hub\n",
    "!pip install huggingface_sb3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2977e0",
   "metadata": {},
   "source": [
    "## 1.3 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e140f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO, SAC\n",
    "from stable_baselines3.ppo.policies import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c1201",
   "metadata": {},
   "source": [
    "# 2. Premiers essais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --algo DQN --env LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp logs/dqn/LunarLander-v2_1/best_model.zip ./data/policies/LunarLander-v2#dqn#dqn1.zip\n",
    "!python sb3_evaluator.py\n",
    "!rm ./data/policies/LunarLander-v2#dqn#dqn1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --algo PPO --env LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp logs/ppo/LunarLander-v2_1/best_model.zip ./data/policies/LunarLander-v2#ppo#ppo1.zip\n",
    "!python sb3_evaluator.py\n",
    "!rm ./data/policies/LunarLander-v2#ppo#ppo1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --algo PPO --env LunarLanderContinuous-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp logs/ppo/LunarLanderContinuous-v2_1/best_model.zip ./data/policies/LunarLanderContinuous-v2#ppo#ppo1.zip\n",
    "!python sb3_evaluator.py\n",
    "!rm ./data/policies/LunarLanderContinuous-v2#ppo#ppo1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --algo SAC --env LunarLanderContinuous-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp logs/ppo/LunarLanderContinuous-v2_1/best_model.zip ./data/policies/LunarLanderContinuous-v2#sac#sac1.zip\n",
    "!python sb3_evaluator.py\n",
    "!rm ./data/policies/LunarLanderContinuous-v2#sac#sac1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3be563",
   "metadata": {},
   "source": [
    "# 3. Optimisation des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636cd096",
   "metadata": {},
   "source": [
    "## 3.1 Optimisation avec les scripts sb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --algo ppo --env LunarLander-v2 -n 100000 -optimize --n-trials 10000 --n-jobs 2 --sampler tpe --pruner median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --algo sac --env LunarLanderContinuous-v2 -n 100000 -optimize --n-trials 10000 --n-jobs 2 --sampler tpe --pruner median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161d910",
   "metadata": {},
   "source": [
    "## 3.2 Optimisation LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "N_TIMESTEPS = 100000\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 3\n",
    "ENV_ID = \"LunarLander-v2\"\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ppo_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"Sampler for PPO hyperparameters.\"\"\"\n",
    "    n_steps = 2 ** trial.suggest_int(\"n_steps\", 3, 11)\n",
    "    batch_size = 2 ** trial.suggest_int(\"batch_size\", 5, 9)\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.8, 0.83, 0.85, 0.87, 0.9, 0.93, 0.95, 0.98])\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999, log=True)\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 4, 20)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0, 0.06)\n",
    "    learning_rate =  trial.suggest_float(\"lr\", 1e-7, 0.001, log=True)\n",
    "    clip_range = trial.suggest_float(\"clip_range\", 0, 1)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5, log=True)\n",
    "    vf_coef = trial.suggest_float(\"vf_coef\", 0, 1)\n",
    "    \n",
    "    log_std_init = trial.suggest_float(\"log_std_init\", -4, -1)\n",
    "    ortho_init = False\n",
    "    activation_fn = nn.ReLU\n",
    "    which_net_arch = trial.suggest_categorical(\"net_arch\", [\"big\", \"small\"])\n",
    "    \n",
    "    if which_net_arch == \"big\":\n",
    "        net_arch=[dict(pi=[256, 256], vf=[256, 256])]\n",
    "    else:\n",
    "        net_arch=[dict(pi=[64, 64], vf=[64, 64])]\n",
    "    activation_fn = nn.ReLU\n",
    "    ortho_init = False\n",
    "    \n",
    "    # Display true values\n",
    "    trial.set_user_attr(\"gamma_\", gamma)\n",
    "    trial.set_user_attr(\"gae_lambda_\", gae_lambda)\n",
    "    trial.set_user_attr(\"n_steps\", n_steps)\n",
    "\n",
    "    return {\n",
    "        \"n_steps\": n_steps,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"gae_lambda\": gae_lambda, \n",
    "        \"gamma\": gamma,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"clip_range\": clip_range,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"vf_coef\": vf_coef,\n",
    "        \"policy_kwargs\": {\n",
    "            \"net_arch\": net_arch,\n",
    "            \"activation_fn\": activation_fn,\n",
    "            \"ortho_init\": ortho_init,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    kwargs.update(sample_ppo_params(trial))\n",
    "    model = PPO(**kwargs)\n",
    "    eval_env = gym.make(ENV_ID)\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=EVAL_FREQ, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73554cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3)\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1c64a",
   "metadata": {},
   "source": [
    "## 3.3 Optimisation LunarLanderContinuous-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ccd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "N_TIMESTEPS = 50000\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 3\n",
    "ENV_ID = \"LunarLanderContinuous-v2\"\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sac_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"Sampler for SAC hyperparameters.\"\"\"\n",
    "    # policy, env \n",
    "    \n",
    "    # (Union[float, Callable[[float], float]]) – learning rate for adam optimizer,  \n",
    "    # the same learning rate will be used for all networks (Q-Values, Actor and Value \n",
    "    # function) it can be a function of the current progress remaining (from 1 to 0)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "    # INT - size of the replay buffer\n",
    "    buffer_size = 2 ** trial.suggest_int(\"buffer_size\", 17, 21)\n",
    "    # INT - how many steps of the model to collect transitions for before learning starts\n",
    "    learning_starts = 100 * trial.suggest_int(\"learning_starts\", 1, 50)\n",
    "    # INT - Minibatch size for each gradient update\n",
    "    batch_size = 256\n",
    "    # FLOAT - the soft update coefficient (“Polyak update”, between 0 and 1)\n",
    "    tau = trial.suggest_float(\"tau\", 0.0001, 0.2, log=True)\n",
    "    # FLOAT - the discount factor\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999, log=True)\n",
    "    # INT - Update the model every train_freq steps\n",
    "    train_freq = trial.suggest_int(\"train_freq\", 1, 10)\n",
    "    # INT - How many gradient steps to do after each rollout\n",
    "    gradient_steps = trial.suggest_int(\"gradient_steps\", 1, 10)\n",
    "    # FLOAT - Entropy regularization coefficient\n",
    "    # ent_coef = trial.suggest_float(\"ent_coef\", 0.05, 0.15, log=True)\n",
    "    # INT - update the target network every target_network_update_freq gradient steps.\n",
    "    # target_update_interval = trial.suggest_int(\"target_update_interval\", 1, 100)\n",
    "    # FLOAT - target entropy when learning ent_coef\n",
    "    # target_entropy = trial.suggest_float(\"target_entropy\", 0.05, 0.15, log=True)\n",
    "    # BOOL - Whether to use generalized State Dependent Exploration (gSDE) instead of action noise exploration\n",
    "    use_sde = True\n",
    "    # INT - Sample a new noise matrix every n steps when using gSDE\n",
    "    sde_sample_freq = trial.suggest_int(\"sde_sample_freq\", 1, 10)\n",
    "    # BOOL - Whether to use gSDE instead of uniform sampling during the warm up phase (before learning starts)\n",
    "    use_sde_at_warmup = trial.suggest_categorical(\"use_sde_at_warmup\", [True, False])\n",
    "    # Display true values\n",
    "    trial.set_user_attr(\"gamma_\", gamma)\n",
    "\n",
    "    return {\n",
    "        \"learning_rate\" : learning_rate, \n",
    "        \"buffer_size\" : buffer_size, \n",
    "        \"learning_starts\" : learning_starts,\n",
    "        \"batch_size\" : batch_size,\n",
    "        \"tau\" : tau,\n",
    "        \"gamma\" : gamma,\n",
    "        \"train_freq\" : train_freq,\n",
    "        \"gradient_steps\" : gradient_steps,\n",
    "        \"use_sde\" : use_sde,\n",
    "        \"sde_sample_freq\" : sde_sample_freq,\n",
    "        \"use_sde_at_warmup\" : use_sde_at_warmup,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    kwargs.update(sample_sac_params(trial))\n",
    "    model = SAC(**kwargs)\n",
    "    eval_env = gym.make(ENV_ID)\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=EVAL_FREQ, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c191a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3)\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed16393",
   "metadata": {},
   "source": [
    "# 4. Modification dynamique des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f2952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb8ad7b",
   "metadata": {},
   "source": [
    "## 4.1 Learning rate pour PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5be366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(initial_value):\n",
    "    if isinstance(initial_value, str):\n",
    "        initial_value = float(initial_value)\n",
    "\n",
    "    def func(progress):\n",
    "        return progress * initial_value\n",
    "\n",
    "    return func\n",
    "\n",
    "def lrsched():\n",
    "    def reallr(progress):\n",
    "        lr = 0.0004\n",
    "        if progress < 0.8:\n",
    "            lr = 0.0003\n",
    "        if progress < 0.6:\n",
    "            lr = 0.0002\n",
    "        if progress < 0.4:\n",
    "            lr = 0.0001\n",
    "        if progress < 0.2:\n",
    "            lr = 0.00005\n",
    "        return lr\n",
    "    return reallr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d7575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env_id = \"LunarLander-v2\"\n",
    "n_envs = 32\n",
    "env = make_vec_env(env_id, n_envs=n_envs)\n",
    "eval_envs = make_vec_env(env_id, n_envs=4)\n",
    "\n",
    "eval_freq = int(1e5)\n",
    "eval_freq = max(eval_freq // n_envs, 1)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_envs,\n",
    "    best_model_save_path=\"./\",\n",
    "    eval_freq=eval_freq,\n",
    "    n_eval_episodes=10,\n",
    ")\n",
    "\n",
    "model_ppo = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    n_steps=2048,\n",
    "    batch_size=256,\n",
    "    gamma=0.999,\n",
    "    gae_lambda=0.98,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    n_epochs=8,\n",
    "    learning_rate=lrsched(),\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(net_arch=[dict(pi=[64, 64, 64, 64], vf=[64])]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1852c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=34464, episode_reward=46.93 +/- 116.23\n",
      "Episode length: 244.20 +/- 233.99\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 244      |\n",
      "|    mean_reward     | 46.9     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 34464    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 90.9     |\n",
      "|    ep_rew_mean     | -143     |\n",
      "| time/              |          |\n",
      "|    fps             | 3852     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.5        |\n",
      "|    ep_rew_mean          | -108        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3593        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009018002 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.0047     |\n",
      "|    learning_rate        | 0.0004      |\n",
      "|    loss                 | 783         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=134464, episode_reward=-139.75 +/- 46.51\n",
      "Episode length: 403.20 +/- 156.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 403         |\n",
      "|    mean_reward          | -140        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 134464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012496803 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.031      |\n",
      "|    learning_rate        | 0.0004      |\n",
      "|    loss                 | 263         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    value_loss           | 581         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -69.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 3125     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=234464, episode_reward=-119.46 +/- 46.40\n",
      "Episode length: 677.20 +/- 311.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 677         |\n",
      "|    mean_reward          | -119        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 234464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011989228 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.0004      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -57.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 2824     |\n",
      "|    iterations      | 4        |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 262144   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 128        |\n",
      "|    ep_rew_mean          | -34.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2796       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01404826 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.0004     |\n",
      "|    loss                 | 81.4       |\n",
      "|    n_updates            | 32         |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 192        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=334464, episode_reward=-131.89 +/- 51.23\n",
      "Episode length: 742.80 +/- 300.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 743         |\n",
      "|    mean_reward          | -132        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 334464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012584256 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0004      |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | -7.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 2227     |\n",
      "|    iterations      | 6        |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 393216   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=434464, episode_reward=-81.17 +/- 79.81\n",
      "Episode length: 948.40 +/- 103.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 948          |\n",
      "|    mean_reward          | -81.2        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 434464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105843805 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 82           |\n",
      "|    n_updates            | 48           |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 546      |\n",
      "|    ep_rew_mean     | 2.59     |\n",
      "| time/              |          |\n",
      "|    fps             | 1782     |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 257      |\n",
      "|    total_timesteps | 458752   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 751          |\n",
      "|    ep_rew_mean          | 30.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1602         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 327          |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081521105 |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=534464, episode_reward=5.16 +/- 94.70\n",
      "Episode length: 842.70 +/- 163.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 843          |\n",
      "|    mean_reward          | 5.16         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 534464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072993087 |\n",
      "|    clip_fraction        | 0.0749       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 64           |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 71.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 804      |\n",
      "|    ep_rew_mean     | 46.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 1437     |\n",
      "|    iterations      | 9        |\n",
      "|    time_elapsed    | 410      |\n",
      "|    total_timesteps | 589824   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=634464, episode_reward=121.88 +/- 67.01\n",
      "Episode length: 820.10 +/- 136.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 820          |\n",
      "|    mean_reward          | 122          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 634464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060766377 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 72           |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 77.3         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 870      |\n",
      "|    ep_rew_mean     | 56       |\n",
      "| time/              |          |\n",
      "|    fps             | 1342     |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 488      |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 876        |\n",
      "|    ep_rew_mean          | 58.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1300       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 554        |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00689027 |\n",
      "|    clip_fraction        | 0.0697     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.9        |\n",
      "|    learning_rate        | 0.0004     |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    value_loss           | 86.8       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=734464, episode_reward=194.14 +/- 28.37\n",
      "Episode length: 593.60 +/- 92.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 594         |\n",
      "|    mean_reward          | 194         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 734464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005824158 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0004      |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 867      |\n",
      "|    ep_rew_mean     | 76       |\n",
      "| time/              |          |\n",
      "|    fps             | 1259     |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 624      |\n",
      "|    total_timesteps | 786432   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=834464, episode_reward=180.85 +/- 73.86\n",
      "Episode length: 542.70 +/- 44.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 543          |\n",
      "|    mean_reward          | 181          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 834464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065726237 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 96           |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 59.4         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 902      |\n",
      "|    ep_rew_mean     | 96.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 1228     |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 693      |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 927          |\n",
      "|    ep_rew_mean          | 98.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1210         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 757          |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053950963 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=934464, episode_reward=163.24 +/- 89.51\n",
      "Episode length: 532.00 +/- 51.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 532          |\n",
      "|    mean_reward          | 163          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 934464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067023514 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0004       |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 112          |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 927      |\n",
      "|    ep_rew_mean     | 99.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 1180     |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 832      |\n",
      "|    total_timesteps | 983040   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1034464, episode_reward=184.14 +/- 69.70\n",
      "Episode length: 515.70 +/- 26.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 516         |\n",
      "|    mean_reward          | 184         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1034464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005073311 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0004      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 858      |\n",
      "|    ep_rew_mean     | 87       |\n",
      "| time/              |          |\n",
      "|    fps             | 1156     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 906      |\n",
      "|    total_timesteps | 1048576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 858         |\n",
      "|    ep_rew_mean          | 87.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1149        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 969         |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006430888 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1134464, episode_reward=200.11 +/- 27.49\n",
      "Episode length: 554.10 +/- 135.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 554          |\n",
      "|    mean_reward          | 200          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1134464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038730372 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 70.1         |\n",
      "|    n_updates            | 136          |\n",
      "|    policy_gradient_loss | -0.000941    |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 900      |\n",
      "|    ep_rew_mean     | 93.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 1134     |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 1039     |\n",
      "|    total_timesteps | 1179648  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1234464, episode_reward=204.14 +/- 21.17\n",
      "Episode length: 541.80 +/- 60.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 542          |\n",
      "|    mean_reward          | 204          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1234464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047998037 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 144          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 942      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    fps             | 1118     |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 1113     |\n",
      "|    total_timesteps | 1245184  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 900          |\n",
      "|    ep_rew_mean          | 101          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1104         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1186         |\n",
      "|    total_timesteps      | 1310720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042795897 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.73         |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1334464, episode_reward=200.26 +/- 45.30\n",
      "Episode length: 604.20 +/- 136.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 604          |\n",
      "|    mean_reward          | 200          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1334464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043505756 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 919      |\n",
      "|    ep_rew_mean     | 107      |\n",
      "| time/              |          |\n",
      "|    fps             | 1089     |\n",
      "|    iterations      | 21       |\n",
      "|    time_elapsed    | 1263     |\n",
      "|    total_timesteps | 1376256  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1434464, episode_reward=214.92 +/- 19.78\n",
      "Episode length: 583.80 +/- 53.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 584          |\n",
      "|    mean_reward          | 215          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1434464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061222445 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 168          |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 950      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    fps             | 1073     |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 1343     |\n",
      "|    total_timesteps | 1441792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 971         |\n",
      "|    ep_rew_mean          | 126         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1064        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1415        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004415856 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.72        |\n",
      "|    n_updates            | 176         |\n",
      "|    policy_gradient_loss | -0.000991   |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1534464, episode_reward=200.99 +/- 42.91\n",
      "Episode length: 609.00 +/- 154.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 609          |\n",
      "|    mean_reward          | 201          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1534464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040830863 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.33         |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 945      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    fps             | 1053     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 1492     |\n",
      "|    total_timesteps | 1572864  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1634464, episode_reward=219.23 +/- 37.56\n",
      "Episode length: 555.50 +/- 160.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 556         |\n",
      "|    mean_reward          | 219         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1634464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005189411 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 966      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    fps             | 1045     |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1567     |\n",
      "|    total_timesteps | 1638400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 942         |\n",
      "|    ep_rew_mean          | 130         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1037        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1641        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004661501 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1734464, episode_reward=223.50 +/- 20.67\n",
      "Episode length: 569.80 +/- 100.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 570          |\n",
      "|    mean_reward          | 223          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1734464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064068697 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 208          |\n",
      "|    policy_gradient_loss | -0.000826    |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 917      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    fps             | 1032     |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 1714     |\n",
      "|    total_timesteps | 1769472  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1834464, episode_reward=229.33 +/- 19.98\n",
      "Episode length: 462.60 +/- 90.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 463         |\n",
      "|    mean_reward          | 229         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1834464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005266466 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.77        |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 948      |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    fps             | 1027     |\n",
      "|    iterations      | 28       |\n",
      "|    time_elapsed    | 1785     |\n",
      "|    total_timesteps | 1835008  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 954          |\n",
      "|    ep_rew_mean          | 135          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1022         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 1859         |\n",
      "|    total_timesteps      | 1900544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041096364 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.965       |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.47         |\n",
      "|    n_updates            | 224          |\n",
      "|    policy_gradient_loss | -0.0003      |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1934464, episode_reward=225.34 +/- 16.79\n",
      "Episode length: 516.90 +/- 130.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 517         |\n",
      "|    mean_reward          | 225         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1934464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004903987 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 973      |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    fps             | 1014     |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1937     |\n",
      "|    total_timesteps | 1966080  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 977          |\n",
      "|    ep_rew_mean          | 132          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1012         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 2006         |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054846676 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.974       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.82         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2034464, episode_reward=226.66 +/- 24.79\n",
      "Episode length: 496.90 +/- 98.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 497         |\n",
      "|    mean_reward          | 227         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2034464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004617874 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.961      |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0002      |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 994      |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    fps             | 1002     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 2092     |\n",
      "|    total_timesteps | 2097152  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=2134464, episode_reward=231.88 +/- 20.89\n",
      "Episode length: 472.80 +/- 78.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 473         |\n",
      "|    mean_reward          | 232         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2134464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003520199 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.941      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0002      |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 990      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    fps             | 998      |\n",
      "|    iterations      | 33       |\n",
      "|    time_elapsed    | 2166     |\n",
      "|    total_timesteps | 2162688  |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_ppo.learn(total_timesteps=5000000, callback=eval_callback)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a856aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv best_model.zip ./data/policies/LunarLander-v2#ppo#Corcoral_Kostadinovic.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fc53847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LunarLander-v2#ppo#Corcoral_Kostadinovic.zip\n",
      "ppo\n",
      "{'normalize': False}\n",
      "Hall of fame\n",
      "Environment : LunarLander-v2\n",
      "team:  Corcoral_Kostadinovic  \t \t algo: ppo  \t \t mean score:  267.797661725 std:  20.90785038629794\n",
      "Time : 24s 755ms\n"
     ]
    }
   ],
   "source": [
    "!python sb3_evaluator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa882cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./data/policies/LunarLander-v2#ppo#Corcoral_Kostadinovic.zip ./rl-trained-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12d958",
   "metadata": {},
   "source": [
    "## 4.2 Learning rate pour SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff965d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(initial_value):\n",
    "\n",
    "    if isinstance(initial_value, str):\n",
    "        initial_value = float(initial_value)\n",
    "\n",
    "    def func(progress):\n",
    "        return progress * initial_value\n",
    "\n",
    "    return func\n",
    "\n",
    "def lrsched():\n",
    "    def reallr(progress):\n",
    "        lr = 0.005\n",
    "        if progress < 0.8:\n",
    "            lr = 0.003\n",
    "        if progress < 0.6:\n",
    "            lr = 0.001\n",
    "        if progress < 0.4:\n",
    "            lr = 0.0005\n",
    "        if progress < 0.2:\n",
    "            lr = 0.0001\n",
    "        return lr\n",
    "    return reallr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a086bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env_id = \"LunarLanderContinuous-v2\"\n",
    "n_envs = 32\n",
    "env = make_vec_env(env_id, n_envs=n_envs)\n",
    "eval_envs = make_vec_env(env_id, n_envs=4)\n",
    "\n",
    "eval_freq = int(1e5)\n",
    "eval_freq = max(eval_freq // n_envs, 1)\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_envs,\n",
    "    best_model_save_path=\"./\",\n",
    "    eval_freq=eval_freq,\n",
    "    n_eval_episodes=10,\n",
    ")\n",
    "\n",
    "model_sac = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    train_freq=9,\n",
    "    gradient_steps=8,\n",
    "    sde_sample_freq=5,\n",
    "    use_sde_at_warmup=False,\n",
    "    use_sde=False,\n",
    "    batch_size=256,\n",
    "    buffer_size=262144,\n",
    "    ent_coef='auto',\n",
    "    gamma=0.9877986493994404,\n",
    "    tau=0.0039251709137456195,\n",
    "    learning_rate=lrsched(),\n",
    "    learning_starts=2800,\n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(net_arch=[400, 300]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e11cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 73.8     |\n",
      "|    ep_rew_mean     | -82.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 3914     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2560     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.5     |\n",
      "|    ep_rew_mean     | -123     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 2394     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2848     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 83.8     |\n",
      "|    ep_rew_mean     | -151     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 2125     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3008     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.744   |\n",
      "|    critic_loss     | 37.4     |\n",
      "|    ent_coef        | 0.983    |\n",
      "|    ent_coef_loss   | -0.057   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8        |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 86.9     |\n",
      "|    ep_rew_mean     | -194     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 2159     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3168     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 90       |\n",
      "|    ep_rew_mean     | -201     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 2110     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3392     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.552   |\n",
      "|    critic_loss     | 70.3     |\n",
      "|    ent_coef        | 0.944    |\n",
      "|    ent_coef_loss   | -0.192   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 16       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94       |\n",
      "|    ep_rew_mean     | -205     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 2064     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3680     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.604   |\n",
      "|    critic_loss     | 49.2     |\n",
      "|    ent_coef        | 0.907    |\n",
      "|    ent_coef_loss   | -0.322   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 24       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 99.2     |\n",
      "|    ep_rew_mean     | -209     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 1990     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 4544     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.435   |\n",
      "|    critic_loss     | 41.3     |\n",
      "|    ent_coef        | 0.804    |\n",
      "|    ent_coef_loss   | -0.702   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 48       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -196     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 1949     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 4736     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.58    |\n",
      "|    critic_loss     | 47       |\n",
      "|    ent_coef        | 0.773    |\n",
      "|    ent_coef_loss   | -0.76    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 56       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -186     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 1890     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 5248     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.504   |\n",
      "|    critic_loss     | 57.5     |\n",
      "|    ent_coef        | 0.716    |\n",
      "|    ent_coef_loss   | -1.01    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 72       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -177     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 1891     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 5920     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.45    |\n",
      "|    critic_loss     | 54.3     |\n",
      "|    ent_coef        | 0.664    |\n",
      "|    ent_coef_loss   | -1.08    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 88       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -169     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 1844     |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 7424     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.29    |\n",
      "|    critic_loss     | 42.8     |\n",
      "|    ent_coef        | 0.552    |\n",
      "|    ent_coef_loss   | -1.58    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 128      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -166     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 1717     |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 8384     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.0871  |\n",
      "|    critic_loss     | 25.5     |\n",
      "|    ent_coef        | 0.475    |\n",
      "|    ent_coef_loss   | -1.71    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 160      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -163     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 1703     |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 8736     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.151    |\n",
      "|    critic_loss     | 49.2     |\n",
      "|    ent_coef        | 0.459    |\n",
      "|    ent_coef_loss   | -2.21    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 168      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -169     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 1704     |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 9440     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.715    |\n",
      "|    critic_loss     | 48.1     |\n",
      "|    ent_coef        | 0.426    |\n",
      "|    ent_coef_loss   | -2.26    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 184      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 118      |\n",
      "|    ep_rew_mean     | -178     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 1670     |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 10144    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.228    |\n",
      "|    critic_loss     | 24.9     |\n",
      "|    ent_coef        | 0.386    |\n",
      "|    ent_coef_loss   | -2.56    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 208      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 122      |\n",
      "|    ep_rew_mean     | -185     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 1667     |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 10592    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.751    |\n",
      "|    critic_loss     | 46.5     |\n",
      "|    ent_coef        | 0.373    |\n",
      "|    ent_coef_loss   | -2.58    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 216      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 125      |\n",
      "|    ep_rew_mean     | -181     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 1646     |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 11392    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.778    |\n",
      "|    critic_loss     | 48.1     |\n",
      "|    ent_coef        | 0.339    |\n",
      "|    ent_coef_loss   | -2.57    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 240      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 129      |\n",
      "|    ep_rew_mean     | -183     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 1625     |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.533    |\n",
      "|    critic_loss     | 39.4     |\n",
      "|    ent_coef        | 0.301    |\n",
      "|    ent_coef_loss   | -2.62    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 272      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 131      |\n",
      "|    ep_rew_mean     | -183     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 1620     |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 12864    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.806    |\n",
      "|    critic_loss     | 40.4     |\n",
      "|    ent_coef        | 0.292    |\n",
      "|    ent_coef_loss   | -2.38    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 280      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 136      |\n",
      "|    ep_rew_mean     | -180     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 1625     |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 13504    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.586    |\n",
      "|    critic_loss     | 42.5     |\n",
      "|    ent_coef        | 0.274    |\n",
      "|    ent_coef_loss   | -2.79    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 296      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 136      |\n",
      "|    ep_rew_mean     | -181     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 1609     |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 14560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.59     |\n",
      "|    critic_loss     | 29.7     |\n",
      "|    ent_coef        | 0.243    |\n",
      "|    ent_coef_loss   | -2.43    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 328      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 138      |\n",
      "|    ep_rew_mean     | -179     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 1601     |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 15456    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.34     |\n",
      "|    critic_loss     | 27.9     |\n",
      "|    ent_coef        | 0.223    |\n",
      "|    ent_coef_loss   | -2.25    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 352      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 140      |\n",
      "|    ep_rew_mean     | -182     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 1587     |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 16352    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.963    |\n",
      "|    critic_loss     | 33.4     |\n",
      "|    ent_coef        | 0.204    |\n",
      "|    ent_coef_loss   | -2.01    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 376      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 143      |\n",
      "|    ep_rew_mean     | -185     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 1572     |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 17056    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.33     |\n",
      "|    critic_loss     | 39.3     |\n",
      "|    ent_coef        | 0.19     |\n",
      "|    ent_coef_loss   | -2.23    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 400      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 146      |\n",
      "|    ep_rew_mean     | -187     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 1553     |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 18240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.62     |\n",
      "|    critic_loss     | 40.1     |\n",
      "|    ent_coef        | 0.172    |\n",
      "|    ent_coef_loss   | -1.17    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 432      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 152      |\n",
      "|    ep_rew_mean     | -199     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 1534     |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 18784    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.59     |\n",
      "|    critic_loss     | 26.3     |\n",
      "|    ent_coef        | 0.165    |\n",
      "|    ent_coef_loss   | -2.66    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 448      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 156      |\n",
      "|    ep_rew_mean     | -198     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 1516     |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 19808    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.04     |\n",
      "|    critic_loss     | 19       |\n",
      "|    ent_coef        | 0.154    |\n",
      "|    ent_coef_loss   | -1.96    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 472      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 160      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 1472     |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 21088    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.18     |\n",
      "|    critic_loss     | 23.8     |\n",
      "|    ent_coef        | 0.141    |\n",
      "|    ent_coef_loss   | -2.51    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 512      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 163      |\n",
      "|    ep_rew_mean     | -208     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 1464     |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 21600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.74     |\n",
      "|    critic_loss     | 37.1     |\n",
      "|    ent_coef        | 0.138    |\n",
      "|    ent_coef_loss   | -2.15    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 520      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 167      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 1453     |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 22144    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.77     |\n",
      "|    critic_loss     | 32.1     |\n",
      "|    ent_coef        | 0.133    |\n",
      "|    ent_coef_loss   | -2.05    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 536      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 171      |\n",
      "|    ep_rew_mean     | -219     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 1436     |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 22624    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.87     |\n",
      "|    critic_loss     | 33.7     |\n",
      "|    ent_coef        | 0.128    |\n",
      "|    ent_coef_loss   | -1.97    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 552      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 177      |\n",
      "|    ep_rew_mean     | -225     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 1426     |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 23648    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.1      |\n",
      "|    critic_loss     | 46       |\n",
      "|    ent_coef        | 0.123    |\n",
      "|    ent_coef_loss   | -1.44    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 584      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -237     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 1423     |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 23936    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.31     |\n",
      "|    critic_loss     | 24.6     |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | -0.616   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 592      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | -246     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 1426     |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 24736    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.24     |\n",
      "|    critic_loss     | 23.5     |\n",
      "|    ent_coef        | 0.119    |\n",
      "|    ent_coef_loss   | -2.44    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 608      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | -253     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 1414     |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 26176    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.91     |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    ent_coef        | 0.111    |\n",
      "|    ent_coef_loss   | -2.19    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 648      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 192      |\n",
      "|    ep_rew_mean     | -262     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 1405     |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 27040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.08     |\n",
      "|    critic_loss     | 38.3     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -1.38    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 672      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | -267     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 1396     |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 27872    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.55     |\n",
      "|    critic_loss     | 51.4     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.971   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 696      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | -277     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 1391     |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 28608    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.9      |\n",
      "|    critic_loss     | 28.1     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | -0.902   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 720      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | -280     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 1393     |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 29088    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.46     |\n",
      "|    critic_loss     | 38.3     |\n",
      "|    ent_coef        | 0.101    |\n",
      "|    ent_coef_loss   | -1.21    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 728      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | -279     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 1382     |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 30720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.32     |\n",
      "|    critic_loss     | 20.9     |\n",
      "|    ent_coef        | 0.0977   |\n",
      "|    ent_coef_loss   | -0.911   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 776      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -279     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 1362     |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32032    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.83     |\n",
      "|    critic_loss     | 35.8     |\n",
      "|    ent_coef        | 0.0964   |\n",
      "|    ent_coef_loss   | -0.643   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 816      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | -283     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 1356     |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32288    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.72     |\n",
      "|    critic_loss     | 26.8     |\n",
      "|    ent_coef        | 0.0961   |\n",
      "|    ent_coef_loss   | -1.25    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 824      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -284     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 1355     |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 32736    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.92     |\n",
      "|    critic_loss     | 18.4     |\n",
      "|    ent_coef        | 0.0954   |\n",
      "|    ent_coef_loss   | 1.13     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 832      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 202      |\n",
      "|    ep_rew_mean     | -284     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 1349     |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 33536    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.7      |\n",
      "|    critic_loss     | 32.6     |\n",
      "|    ent_coef        | 0.096    |\n",
      "|    ent_coef_loss   | -0.31    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 856      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 202      |\n",
      "|    ep_rew_mean     | -287     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 1346     |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 34752    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.03     |\n",
      "|    critic_loss     | 25.6     |\n",
      "|    ent_coef        | 0.0948   |\n",
      "|    ent_coef_loss   | 0.157    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 888      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | -290     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 1339     |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 35712    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.55     |\n",
      "|    critic_loss     | 44.1     |\n",
      "|    ent_coef        | 0.0946   |\n",
      "|    ent_coef_loss   | -0.99    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 912      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | -293     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 1334     |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 36608    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.11     |\n",
      "|    critic_loss     | 22.3     |\n",
      "|    ent_coef        | 0.0932   |\n",
      "|    ent_coef_loss   | 0.936    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 944      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | -291     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 1331     |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 37536    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.22     |\n",
      "|    critic_loss     | 29.4     |\n",
      "|    ent_coef        | 0.0946   |\n",
      "|    ent_coef_loss   | 0.271    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 968      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | -294     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 1315     |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 39040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.17     |\n",
      "|    critic_loss     | 21.6     |\n",
      "|    ent_coef        | 0.0968   |\n",
      "|    ent_coef_loss   | -0.726   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1008     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 211      |\n",
      "|    ep_rew_mean     | -296     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 1301     |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 40064    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.76     |\n",
      "|    critic_loss     | 14.5     |\n",
      "|    ent_coef        | 0.0991   |\n",
      "|    ent_coef_loss   | -0.668   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1040     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 215      |\n",
      "|    ep_rew_mean     | -291     |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 1296     |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 40800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.41     |\n",
      "|    critic_loss     | 21.2     |\n",
      "|    ent_coef        | 0.0983   |\n",
      "|    ent_coef_loss   | -0.379   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1056     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 216      |\n",
      "|    ep_rew_mean     | -294     |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 1292     |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 41312    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.4      |\n",
      "|    critic_loss     | 29.5     |\n",
      "|    ent_coef        | 0.0971   |\n",
      "|    ent_coef_loss   | 0.104    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1072     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 218      |\n",
      "|    ep_rew_mean     | -288     |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 1293     |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 42144    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.31     |\n",
      "|    critic_loss     | 23       |\n",
      "|    ent_coef        | 0.0974   |\n",
      "|    ent_coef_loss   | -0.0867  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1096     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 220      |\n",
      "|    ep_rew_mean     | -284     |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 1295     |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 42560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.17     |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    ent_coef        | 0.0976   |\n",
      "|    ent_coef_loss   | 0.802    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1104     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 221      |\n",
      "|    ep_rew_mean     | -272     |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 1295     |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 44480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.08     |\n",
      "|    critic_loss     | 21.6     |\n",
      "|    ent_coef        | 0.0997   |\n",
      "|    ent_coef_loss   | -0.762   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1160     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 224      |\n",
      "|    ep_rew_mean     | -269     |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 1283     |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 47072    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.41     |\n",
      "|    critic_loss     | 22       |\n",
      "|    ent_coef        | 0.0979   |\n",
      "|    ent_coef_loss   | 0.0606   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1232     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 223      |\n",
      "|    ep_rew_mean     | -263     |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 1263     |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 48928    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.72     |\n",
      "|    critic_loss     | 30.2     |\n",
      "|    ent_coef        | 0.0963   |\n",
      "|    ent_coef_loss   | 1.22     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1280     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 229      |\n",
      "|    ep_rew_mean     | -256     |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 1256     |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 49600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.81     |\n",
      "|    critic_loss     | 20.8     |\n",
      "|    ent_coef        | 0.0967   |\n",
      "|    ent_coef_loss   | 0.204    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1304     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 232      |\n",
      "|    ep_rew_mean     | -254     |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 1247     |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 50784    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.38     |\n",
      "|    critic_loss     | 23       |\n",
      "|    ent_coef        | 0.0979   |\n",
      "|    ent_coef_loss   | 0.811    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1336     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 239      |\n",
      "|    ep_rew_mean     | -249     |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 1243     |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 51328    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.52     |\n",
      "|    critic_loss     | 23.2     |\n",
      "|    ent_coef        | 0.0992   |\n",
      "|    ent_coef_loss   | -0.668   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1352     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 242      |\n",
      "|    ep_rew_mean     | -246     |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 1244     |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 51552    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | -245     |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 1244     |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 52608    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.34     |\n",
      "|    critic_loss     | 14.7     |\n",
      "|    ent_coef        | 0.0993   |\n",
      "|    ent_coef_loss   | -0.433   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1384     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | -238     |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 1247     |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 54144    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.76     |\n",
      "|    critic_loss     | 17.2     |\n",
      "|    ent_coef        | 0.1      |\n",
      "|    ent_coef_loss   | -0.458   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1424     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | -230     |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 1246     |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 55872    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.09     |\n",
      "|    critic_loss     | 16.6     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | 0.446    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1472     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | -230     |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 1239     |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 57760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.48     |\n",
      "|    critic_loss     | 15.5     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | 0.0585   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1528     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | -225     |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 1236     |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 58720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.24     |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | 1.05     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1552     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | -226     |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 1229     |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 60096    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.81     |\n",
      "|    critic_loss     | 18.3     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | -0.259   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1592     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 265      |\n",
      "|    ep_rew_mean     | -228     |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 1220     |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 61600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.46     |\n",
      "|    critic_loss     | 24.5     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.0163  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1632     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 269      |\n",
      "|    ep_rew_mean     | -225     |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 1201     |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 64192    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.18     |\n",
      "|    critic_loss     | 21.1     |\n",
      "|    ent_coef        | 0.107    |\n",
      "|    ent_coef_loss   | -0.043   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1704     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 273      |\n",
      "|    ep_rew_mean     | -224     |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 1197     |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 64608    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.23     |\n",
      "|    critic_loss     | 12       |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -0.975   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1720     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 275      |\n",
      "|    ep_rew_mean     | -219     |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 1190     |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 65952    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.08     |\n",
      "|    critic_loss     | 20.8     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | -0.424   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1752     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 277      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 1186     |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 66656    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.23     |\n",
      "|    critic_loss     | 14       |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | -0.568   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1776     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | -211     |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 1185     |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 67104    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.09     |\n",
      "|    critic_loss     | 18.4     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | 0.471    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1784     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 291      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 1183     |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 68480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.05     |\n",
      "|    critic_loss     | 21.9     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | 0.324    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1824     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | -198     |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 1179     |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 70464    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.54     |\n",
      "|    critic_loss     | 30.9     |\n",
      "|    ent_coef        | 0.112    |\n",
      "|    ent_coef_loss   | 0.657    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 1880     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 1156     |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 74624    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.54     |\n",
      "|    critic_loss     | 15.8     |\n",
      "|    ent_coef        | 0.112    |\n",
      "|    ent_coef_loss   | -0.397   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2000     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | -194     |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 1118     |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 78432    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.77     |\n",
      "|    critic_loss     | 26       |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | 0.52     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2104     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 316      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 1076     |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 82272    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.89     |\n",
      "|    critic_loss     | 23.5     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | 0.19     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 331      |\n",
      "|    ep_rew_mean     | -185     |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 1065     |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 83200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.45     |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | 0.221    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2232     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 345      |\n",
      "|    ep_rew_mean     | -186     |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 1020     |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 87808    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.55     |\n",
      "|    critic_loss     | 23.8     |\n",
      "|    ent_coef        | 0.114    |\n",
      "|    ent_coef_loss   | 0.434    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2360     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 367      |\n",
      "|    ep_rew_mean     | -182     |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 888      |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 98368    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.52     |\n",
      "|    critic_loss     | 16.1     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | -0.165   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2656     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 393      |\n",
      "|    ep_rew_mean     | -172     |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 879      |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 99072    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.58     |\n",
      "|    critic_loss     | 15.1     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | -0.0362  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2672     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-77.14 +/- 36.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -77.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.87     |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    ent_coef        | 0.119    |\n",
      "|    ent_coef_loss   | -0.00612 |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2704     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 420      |\n",
      "|    ep_rew_mean     | -165     |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 677      |\n",
      "|    time_elapsed    | 151      |\n",
      "|    total_timesteps | 102272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.59     |\n",
      "|    critic_loss     | 11.4     |\n",
      "|    ent_coef        | 0.113    |\n",
      "|    ent_coef_loss   | -1.12    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2768     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 448      |\n",
      "|    ep_rew_mean     | -157     |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 666      |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 105184   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.89     |\n",
      "|    critic_loss     | 14.4     |\n",
      "|    ent_coef        | 0.109    |\n",
      "|    ent_coef_loss   | 0.247    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2848     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 475      |\n",
      "|    ep_rew_mean     | -151     |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 643      |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 110432   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.44     |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | 0.0811   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 2992     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 503      |\n",
      "|    ep_rew_mean     | -145     |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 627      |\n",
      "|    time_elapsed    | 182      |\n",
      "|    total_timesteps | 114272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.25     |\n",
      "|    critic_loss     | 25.4     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | 0.188    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3096     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 530      |\n",
      "|    ep_rew_mean     | -139     |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 625      |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 115200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.24     |\n",
      "|    critic_loss     | 19.8     |\n",
      "|    ent_coef        | 0.107    |\n",
      "|    ent_coef_loss   | -0.616   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3120     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 558      |\n",
      "|    ep_rew_mean     | -133     |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 619      |\n",
      "|    time_elapsed    | 193      |\n",
      "|    total_timesteps | 119808   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.76     |\n",
      "|    critic_loss     | 22.2     |\n",
      "|    ent_coef        | 0.106    |\n",
      "|    ent_coef_loss   | -0.567   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3248     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 588      |\n",
      "|    ep_rew_mean     | -131     |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 599      |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 130368   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.63     |\n",
      "|    critic_loss     | 17       |\n",
      "|    ent_coef        | 0.0866   |\n",
      "|    ent_coef_loss   | 0.215    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3544     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 617      |\n",
      "|    ep_rew_mean     | -122     |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 597      |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 131072   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.44     |\n",
      "|    critic_loss     | 7.69     |\n",
      "|    ent_coef        | 0.0887   |\n",
      "|    ent_coef_loss   | -0.0528  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3568     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 648      |\n",
      "|    ep_rew_mean     | -118     |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 590      |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 134272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.94     |\n",
      "|    critic_loss     | 6.29     |\n",
      "|    ent_coef        | 0.0993   |\n",
      "|    ent_coef_loss   | -0.107   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3656     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 677      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 587      |\n",
      "|    time_elapsed    | 233      |\n",
      "|    total_timesteps | 137184   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.91     |\n",
      "|    critic_loss     | 16       |\n",
      "|    ent_coef        | 0.0893   |\n",
      "|    ent_coef_loss   | -0.326   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3736     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 703      |\n",
      "|    ep_rew_mean     | -103     |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 142432   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.97     |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.0843   |\n",
      "|    ent_coef_loss   | -0.392   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3880     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 731      |\n",
      "|    ep_rew_mean     | -102     |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 253      |\n",
      "|    total_timesteps | 146272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.45     |\n",
      "|    critic_loss     | 13.7     |\n",
      "|    ent_coef        | 0.0815   |\n",
      "|    ent_coef_loss   | 0.0979   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 3984     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 758      |\n",
      "|    ep_rew_mean     | -98.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 575      |\n",
      "|    time_elapsed    | 255      |\n",
      "|    total_timesteps | 147200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.47     |\n",
      "|    critic_loss     | 11       |\n",
      "|    ent_coef        | 0.0813   |\n",
      "|    ent_coef_loss   | -0.3     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4016     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 785      |\n",
      "|    ep_rew_mean     | -96      |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 574      |\n",
      "|    time_elapsed    | 264      |\n",
      "|    total_timesteps | 151808   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.84     |\n",
      "|    critic_loss     | 9.83     |\n",
      "|    ent_coef        | 0.0777   |\n",
      "|    ent_coef_loss   | -0.297   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4144     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 813      |\n",
      "|    ep_rew_mean     | -93      |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 563      |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 162368   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.38     |\n",
      "|    critic_loss     | 9.35     |\n",
      "|    ent_coef        | 0.0739   |\n",
      "|    ent_coef_loss   | 0.315    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4432     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 838      |\n",
      "|    ep_rew_mean     | -95.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 562      |\n",
      "|    time_elapsed    | 289      |\n",
      "|    total_timesteps | 163072   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.32     |\n",
      "|    critic_loss     | 7.21     |\n",
      "|    ent_coef        | 0.0737   |\n",
      "|    ent_coef_loss   | -0.484   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4456     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 863      |\n",
      "|    ep_rew_mean     | -93.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 559      |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 166272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.06     |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    ent_coef        | 0.0673   |\n",
      "|    ent_coef_loss   | 1.21     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4544     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 890      |\n",
      "|    ep_rew_mean     | -91.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 557      |\n",
      "|    time_elapsed    | 303      |\n",
      "|    total_timesteps | 169184   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.53     |\n",
      "|    critic_loss     | 9.96     |\n",
      "|    ent_coef        | 0.0744   |\n",
      "|    ent_coef_loss   | 0.00031  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4624     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 918      |\n",
      "|    ep_rew_mean     | -88.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 174432   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.09     |\n",
      "|    critic_loss     | 14.8     |\n",
      "|    ent_coef        | 0.0616   |\n",
      "|    ent_coef_loss   | -0.0358  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4768     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 939      |\n",
      "|    ep_rew_mean     | -83.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 178272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.89     |\n",
      "|    critic_loss     | 11.9     |\n",
      "|    ent_coef        | 0.0558   |\n",
      "|    ent_coef_loss   | -0.686   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4872     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 958      |\n",
      "|    ep_rew_mean     | -78.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 326      |\n",
      "|    total_timesteps | 179200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.51     |\n",
      "|    critic_loss     | 9.55     |\n",
      "|    ent_coef        | 0.0516   |\n",
      "|    ent_coef_loss   | -0.438   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 4904     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 973      |\n",
      "|    ep_rew_mean     | -80.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 336      |\n",
      "|    total_timesteps | 183808   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.02     |\n",
      "|    critic_loss     | 7.05     |\n",
      "|    ent_coef        | 0.0577   |\n",
      "|    ent_coef_loss   | -0.164   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5032     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 990      |\n",
      "|    ep_rew_mean     | -76      |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 542      |\n",
      "|    time_elapsed    | 358      |\n",
      "|    total_timesteps | 194368   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.32     |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    ent_coef        | 0.0548   |\n",
      "|    ent_coef_loss   | -0.75    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5320     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 997      |\n",
      "|    ep_rew_mean     | -77.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 542      |\n",
      "|    time_elapsed    | 359      |\n",
      "|    total_timesteps | 195072   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.54     |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    ent_coef        | 0.0519   |\n",
      "|    ent_coef_loss   | 0.0832   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5344     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -80.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 541      |\n",
      "|    time_elapsed    | 366      |\n",
      "|    total_timesteps | 198272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.99     |\n",
      "|    critic_loss     | 8.19     |\n",
      "|    ent_coef        | 0.0506   |\n",
      "|    ent_coef_loss   | -0.343   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5432     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-122.34 +/- 38.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -122     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.22     |\n",
      "|    critic_loss     | 7.45     |\n",
      "|    ent_coef        | 0.0501   |\n",
      "|    ent_coef_loss   | 0.93     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5480     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -82.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 511      |\n",
      "|    time_elapsed    | 393      |\n",
      "|    total_timesteps | 201184   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.18     |\n",
      "|    critic_loss     | 7.73     |\n",
      "|    ent_coef        | 0.0549   |\n",
      "|    ent_coef_loss   | 0.33     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5512     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 983      |\n",
      "|    ep_rew_mean     | -81.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 510      |\n",
      "|    time_elapsed    | 400      |\n",
      "|    total_timesteps | 204480   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.94     |\n",
      "|    critic_loss     | 6.89     |\n",
      "|    ent_coef        | 0.0505   |\n",
      "|    ent_coef_loss   | -1.19    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5600     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 983      |\n",
      "|    ep_rew_mean     | -83.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 509      |\n",
      "|    time_elapsed    | 409      |\n",
      "|    total_timesteps | 208672   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.48     |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    ent_coef        | 0.0537   |\n",
      "|    ent_coef_loss   | -0.5     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5720     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 983      |\n",
      "|    ep_rew_mean     | -84.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 509      |\n",
      "|    time_elapsed    | 413      |\n",
      "|    total_timesteps | 210752   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.68     |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    ent_coef        | 0.0464   |\n",
      "|    ent_coef_loss   | -0.0453  |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5776     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 983      |\n",
      "|    ep_rew_mean     | -84.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 509      |\n",
      "|    time_elapsed    | 416      |\n",
      "|    total_timesteps | 212288   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.58     |\n",
      "|    critic_loss     | 11.6     |\n",
      "|    ent_coef        | 0.0458   |\n",
      "|    ent_coef_loss   | 0.155    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5824     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -85      |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 510      |\n",
      "|    time_elapsed    | 425      |\n",
      "|    total_timesteps | 217216   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.28     |\n",
      "|    critic_loss     | 5.77     |\n",
      "|    ent_coef        | 0.0441   |\n",
      "|    ent_coef_loss   | 0.38     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 5960     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -86.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 456      |\n",
      "|    fps             | 507      |\n",
      "|    time_elapsed    | 446      |\n",
      "|    total_timesteps | 226496   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.91     |\n",
      "|    critic_loss     | 4.64     |\n",
      "|    ent_coef        | 0.0422   |\n",
      "|    ent_coef_loss   | -0.313   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6216     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -87.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 506      |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 227552   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.95     |\n",
      "|    critic_loss     | 18.9     |\n",
      "|    ent_coef        | 0.0401   |\n",
      "|    ent_coef_loss   | 0.579    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6248     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -87.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 464      |\n",
      "|    fps             | 506      |\n",
      "|    time_elapsed    | 455      |\n",
      "|    total_timesteps | 230848   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.03     |\n",
      "|    critic_loss     | 5.14     |\n",
      "|    ent_coef        | 0.0437   |\n",
      "|    ent_coef_loss   | 0.594    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6336     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -88.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 468      |\n",
      "|    fps             | 504      |\n",
      "|    time_elapsed    | 468      |\n",
      "|    total_timesteps | 236256   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.23     |\n",
      "|    critic_loss     | 8.25     |\n",
      "|    ent_coef        | 0.0438   |\n",
      "|    ent_coef_loss   | 0.95     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6488     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -87.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 472      |\n",
      "|    fps             | 503      |\n",
      "|    time_elapsed    | 475      |\n",
      "|    total_timesteps | 239456   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.93     |\n",
      "|    critic_loss     | 7.65     |\n",
      "|    ent_coef        | 0.0388   |\n",
      "|    ent_coef_loss   | -0.975   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6576     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -85.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 476      |\n",
      "|    fps             | 502      |\n",
      "|    time_elapsed    | 482      |\n",
      "|    total_timesteps | 242528   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.22     |\n",
      "|    critic_loss     | 9.48     |\n",
      "|    ent_coef        | 0.0366   |\n",
      "|    ent_coef_loss   | -0.466   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6664     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 974      |\n",
      "|    ep_rew_mean     | -84.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 502      |\n",
      "|    time_elapsed    | 486      |\n",
      "|    total_timesteps | 244288   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.5      |\n",
      "|    critic_loss     | 7.71     |\n",
      "|    ent_coef        | 0.0355   |\n",
      "|    ent_coef_loss   | 0.0779   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6712     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 967      |\n",
      "|    ep_rew_mean     | -84.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 484      |\n",
      "|    fps             | 502      |\n",
      "|    time_elapsed    | 495      |\n",
      "|    total_timesteps | 248992   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.5      |\n",
      "|    critic_loss     | 8.73     |\n",
      "|    ent_coef        | 0.0425   |\n",
      "|    ent_coef_loss   | -0.27    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6840     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 964      |\n",
      "|    ep_rew_mean     | -81.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 488      |\n",
      "|    fps             | 502      |\n",
      "|    time_elapsed    | 497      |\n",
      "|    total_timesteps | 249728   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.61     |\n",
      "|    critic_loss     | 7.85     |\n",
      "|    ent_coef        | 0.0431   |\n",
      "|    ent_coef_loss   | -0.285   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 6864     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 964      |\n",
      "|    ep_rew_mean     | -80.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 492      |\n",
      "|    fps             | 500      |\n",
      "|    time_elapsed    | 517      |\n",
      "|    total_timesteps | 258816   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.2      |\n",
      "|    critic_loss     | 5.27     |\n",
      "|    ent_coef        | 0.04     |\n",
      "|    ent_coef_loss   | -0.452   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7112     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -78.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 496      |\n",
      "|    fps             | 498      |\n",
      "|    time_elapsed    | 525      |\n",
      "|    total_timesteps | 262432   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.9      |\n",
      "|    critic_loss     | 5.76     |\n",
      "|    ent_coef        | 0.0313   |\n",
      "|    ent_coef_loss   | -0.174   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7216     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -78.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 497      |\n",
      "|    time_elapsed    | 538      |\n",
      "|    total_timesteps | 267840   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.07     |\n",
      "|    critic_loss     | 4.12     |\n",
      "|    ent_coef        | 0.0308   |\n",
      "|    ent_coef_loss   | -0.779   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7360     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -75.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 504      |\n",
      "|    fps             | 496      |\n",
      "|    time_elapsed    | 544      |\n",
      "|    total_timesteps | 270432   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.47     |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    ent_coef        | 0.0314   |\n",
      "|    ent_coef_loss   | 0.28     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7432     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -74      |\n",
      "| time/              |          |\n",
      "|    episodes        | 508      |\n",
      "|    fps             | 495      |\n",
      "|    time_elapsed    | 554      |\n",
      "|    total_timesteps | 274528   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.78     |\n",
      "|    critic_loss     | 6.49     |\n",
      "|    ent_coef        | 0.0333   |\n",
      "|    ent_coef_loss   | 0.256    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7552     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -71.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 512      |\n",
      "|    fps             | 495      |\n",
      "|    time_elapsed    | 558      |\n",
      "|    total_timesteps | 276288   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.51     |\n",
      "|    critic_loss     | 4.69     |\n",
      "|    ent_coef        | 0.0302   |\n",
      "|    ent_coef_loss   | -0.351   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7600     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -70.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 516      |\n",
      "|    fps             | 493      |\n",
      "|    time_elapsed    | 569      |\n",
      "|    total_timesteps | 280992   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.16     |\n",
      "|    critic_loss     | 4.47     |\n",
      "|    ent_coef        | 0.0276   |\n",
      "|    ent_coef_loss   | -0.531   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7728     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 963      |\n",
      "|    ep_rew_mean     | -69.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 493      |\n",
      "|    time_elapsed    | 570      |\n",
      "|    total_timesteps | 281728   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.4      |\n",
      "|    critic_loss     | 14.5     |\n",
      "|    ent_coef        | 0.0274   |\n",
      "|    ent_coef_loss   | 1.14     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7752     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 938      |\n",
      "|    ep_rew_mean     | -68.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 524      |\n",
      "|    fps             | 490      |\n",
      "|    time_elapsed    | 591      |\n",
      "|    total_timesteps | 290368   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.15     |\n",
      "|    critic_loss     | 3.42     |\n",
      "|    ent_coef        | 0.0286   |\n",
      "|    ent_coef_loss   | -1.73    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 7992     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 938      |\n",
      "|    ep_rew_mean     | -69.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 528      |\n",
      "|    fps             | 490      |\n",
      "|    time_elapsed    | 593      |\n",
      "|    total_timesteps | 291072   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.65     |\n",
      "|    critic_loss     | 15.1     |\n",
      "|    ent_coef        | 0.0264   |\n",
      "|    ent_coef_loss   | 0.178    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8008     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 938      |\n",
      "|    ep_rew_mean     | -68.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 532      |\n",
      "|    fps             | 489      |\n",
      "|    time_elapsed    | 601      |\n",
      "|    total_timesteps | 294464   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.787    |\n",
      "|    critic_loss     | 4.17     |\n",
      "|    ent_coef        | 0.0228   |\n",
      "|    ent_coef_loss   | -0.624   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8104     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-39.64 +/- 37.08\n",
      "Episode length: 912.50 +/- 262.50\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 912      |\n",
      "|    mean_reward     | -39.6    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 300000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.74     |\n",
      "|    critic_loss     | 5.23     |\n",
      "|    ent_coef        | 0.0169   |\n",
      "|    ent_coef_loss   | 0.685    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8256     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 955      |\n",
      "|    ep_rew_mean     | -69.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 536      |\n",
      "|    fps             | 467      |\n",
      "|    time_elapsed    | 641      |\n",
      "|    total_timesteps | 300256   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.522    |\n",
      "|    critic_loss     | 2.85     |\n",
      "|    ent_coef        | 0.017    |\n",
      "|    ent_coef_loss   | 0.883    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8264     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 955      |\n",
      "|    ep_rew_mean     | -69.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 652      |\n",
      "|    total_timesteps | 304672   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.56     |\n",
      "|    critic_loss     | 4.51     |\n",
      "|    ent_coef        | 0.0167   |\n",
      "|    ent_coef_loss   | 0.905    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8384     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 955      |\n",
      "|    ep_rew_mean     | -68.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 658      |\n",
      "|    total_timesteps | 306752   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.714    |\n",
      "|    critic_loss     | 6.88     |\n",
      "|    ent_coef        | 0.018    |\n",
      "|    ent_coef_loss   | -0.354   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8448     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 955      |\n",
      "|    ep_rew_mean     | -68.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 548      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 662      |\n",
      "|    total_timesteps | 308864   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.7      |\n",
      "|    critic_loss     | 2.79     |\n",
      "|    ent_coef        | 0.0169   |\n",
      "|    ent_coef_loss   | -0.477   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8504     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 954      |\n",
      "|    ep_rew_mean     | -68.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 552      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 671      |\n",
      "|    total_timesteps | 313088   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.826    |\n",
      "|    critic_loss     | 4.04     |\n",
      "|    ent_coef        | 0.0154   |\n",
      "|    ent_coef_loss   | -1.39    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8624     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -67.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 556      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 681      |\n",
      "|    total_timesteps | 318080   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.641    |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    ent_coef        | 0.0131   |\n",
      "|    ent_coef_loss   | -0.317   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -65.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 691      |\n",
      "|    total_timesteps | 322528   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.16     |\n",
      "|    critic_loss     | 1.22     |\n",
      "|    ent_coef        | 0.0134   |\n",
      "|    ent_coef_loss   | -0.508   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8880     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -63.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 564      |\n",
      "|    fps             | 466      |\n",
      "|    time_elapsed    | 696      |\n",
      "|    total_timesteps | 324864   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.15     |\n",
      "|    critic_loss     | 6.32     |\n",
      "|    ent_coef        | 0.0133   |\n",
      "|    ent_coef_loss   | 3.36     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 8944     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -61.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 568      |\n",
      "|    fps             | 465      |\n",
      "|    time_elapsed    | 712      |\n",
      "|    total_timesteps | 331840   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.03     |\n",
      "|    critic_loss     | 2.76     |\n",
      "|    ent_coef        | 0.0108   |\n",
      "|    ent_coef_loss   | 0.522    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9144     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -61.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 572      |\n",
      "|    fps             | 465      |\n",
      "|    time_elapsed    | 717      |\n",
      "|    total_timesteps | 334240   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.991    |\n",
      "|    critic_loss     | 4.76     |\n",
      "|    ent_coef        | 0.0105   |\n",
      "|    ent_coef_loss   | 0.795    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -61.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 576      |\n",
      "|    fps             | 464      |\n",
      "|    time_elapsed    | 727      |\n",
      "|    total_timesteps | 338272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.949    |\n",
      "|    critic_loss     | 3.77     |\n",
      "|    ent_coef        | 0.0113   |\n",
      "|    ent_coef_loss   | -0.517   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9320     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 946      |\n",
      "|    ep_rew_mean     | -61.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 464      |\n",
      "|    time_elapsed    | 733      |\n",
      "|    total_timesteps | 340288   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.01     |\n",
      "|    critic_loss     | 0.969    |\n",
      "|    ent_coef        | 0.0113   |\n",
      "|    ent_coef_loss   | -1.4     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9376     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 953      |\n",
      "|    ep_rew_mean     | -61.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 584      |\n",
      "|    fps             | 464      |\n",
      "|    time_elapsed    | 743      |\n",
      "|    total_timesteps | 345088   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.26     |\n",
      "|    critic_loss     | 0.766    |\n",
      "|    ent_coef        | 0.0093   |\n",
      "|    ent_coef_loss   | -1.49    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9512     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 956      |\n",
      "|    ep_rew_mean     | -63.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 588      |\n",
      "|    fps             | 462      |\n",
      "|    time_elapsed    | 756      |\n",
      "|    total_timesteps | 350080   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.45     |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    ent_coef        | 0.00728  |\n",
      "|    ent_coef_loss   | 1.31     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9648     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 935      |\n",
      "|    ep_rew_mean     | -59.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 592      |\n",
      "|    fps             | 461      |\n",
      "|    time_elapsed    | 764      |\n",
      "|    total_timesteps | 352832   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.06     |\n",
      "|    critic_loss     | 0.536    |\n",
      "|    ent_coef        | 0.00873  |\n",
      "|    ent_coef_loss   | -0.952   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9728     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 936      |\n",
      "|    ep_rew_mean     | -60.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 596      |\n",
      "|    fps             | 461      |\n",
      "|    time_elapsed    | 769      |\n",
      "|    total_timesteps | 354816   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.972    |\n",
      "|    critic_loss     | 0.759    |\n",
      "|    ent_coef        | 0.00719  |\n",
      "|    ent_coef_loss   | -1.4     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9776     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 927      |\n",
      "|    ep_rew_mean     | -60.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 460      |\n",
      "|    time_elapsed    | 774      |\n",
      "|    total_timesteps | 356864   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.35     |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    ent_coef        | 0.0069   |\n",
      "|    ent_coef_loss   | 0.89     |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9840     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 919      |\n",
      "|    ep_rew_mean     | -62.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 604      |\n",
      "|    fps             | 459      |\n",
      "|    time_elapsed    | 784      |\n",
      "|    total_timesteps | 360672   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.43     |\n",
      "|    critic_loss     | 0.595    |\n",
      "|    ent_coef        | 0.00927  |\n",
      "|    ent_coef_loss   | -0.234   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 9944     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 903      |\n",
      "|    ep_rew_mean     | -62.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 608      |\n",
      "|    fps             | 458      |\n",
      "|    time_elapsed    | 794      |\n",
      "|    total_timesteps | 364032   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.14     |\n",
      "|    critic_loss     | 0.836    |\n",
      "|    ent_coef        | 0.00784  |\n",
      "|    ent_coef_loss   | -1.25    |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 10032    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 903      |\n",
      "|    ep_rew_mean     | -61.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 612      |\n",
      "|    fps             | 457      |\n",
      "|    time_elapsed    | 800      |\n",
      "|    total_timesteps | 366432   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.08     |\n",
      "|    critic_loss     | 0.975    |\n",
      "|    ent_coef        | 0.0116   |\n",
      "|    ent_coef_loss   | -0.965   |\n",
      "|    learning_rate   | 0.005    |\n",
      "|    n_updates       | 10104    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_sac.learn(total_timesteps=5000000, callback=eval_callback)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c02acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv best_model.zip ./data/policies/LunarLanderContinuous-v2#ppo#Corcoral_Kostadinovic.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sb3_evaluator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./data/policies/LunarLander-v2#ppo#Corcoral_Kostadinovic.zip ./rl-trained-agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
